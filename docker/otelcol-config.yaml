extensions: #Extendions used to help with troubleshooting
    memory_ballast:
        size_mib: 512
    zpages:
        endpoint: 0.0.0.0:55679
    health_check:

#  Receive data from different sources
receivers:
    zipkin:
    otlp:
        protocols:
            grpc:
            http:
    fluentforward:
        endpoint: 0.0.0.0:8006

# Exporter to Grafana Tempo/Loki, Elasticsearch and Prometheus
exporters:
    zipkin:
        endpoint: http://zipkin:9411/api/v2/spans
        tls:
            insecure: true
    otlp:
        endpoint: tempo:4317
        sending_queue:
            enabled: false
        retry_on_failure:
            enabled: false
        tls:
            insecure: true
    logging:
        loglevel: "DEBUG"
    debug:
        verbosity: detailed
    loki:
        endpoint: http://loki:3100/loki/api/v1/push
        tls:
            insecure: true
    elasticsearch/log:
        endpoints: http://elasticsearch:9200
        logs_index: openetelemetry_log_index

    prometheus:
        endpoint: "0.0.0.0:1234"
#        namespace: test-space
#        const_labels:
#            label1: value1
#            "another label": spaced value
        send_timestamps: true
        metric_expiration: 180m
        enable_open_metrics: true
        add_metric_suffixes: false
        resource_to_telemetry_conversion:
            enabled: true

# Apply filtering before exporting the data.
processors:
    batch:
    transform/before:
        error_mode: ignore
        log_statements:
            - context: log
              statements:
                - set(attributes["msg"], body)
    transform/after:
        error_mode: ignore
        log_statements:
            - context: log
              statements:
                  - set(trace_id.string,attributes["trace_id"])
                  - set(span_id.string,attributes["span_id"])
    attributes:
        actions:
            - action: insert
              key: loki.attribute.labels
              value: app_name, trace_id
#            - action: extract
#              key: fluent.tag
#              pattern: serviceName='(?P<service_name>.*?)'
            - action: extract
              key: msg
              pattern: serviceName='(?P<service_name>.*?)'
#            - action: extract
#              key: fluent.tag
#              pattern: traceID=(?P<trace_id>\w+)
            - action: extract
              key: msg
              pattern: traceID=(?P<trace_id>\w+)
#            - action: extract
#              key: fluent.tag
#              pattern: spanID=(?P<span_id>\w+)
            - action: extract
              key: msg
              pattern: spanID=(?P<span_id>\w+)
#            - action: extract
#              key: fluent.tag
#              pattern: requestId='(?P<request_id>.*?)'
            - action: extract
              key: msg
              pattern: requestId='(?P<request_id>.*?)'
#            - action: delete
#              key: fluent.tag
            - action: delete
              key: msg

# Apply filtering to skip traces for /actuator endpoints
    filter/spans:
        spans:
            exclude:
                match_type: regexp
                attributes:
                    - key: http.url
                      value: /actuator.*

# Apply filtering to skip traces for specific names
    filter/spans2:
        spans:
            exclude:
                match_type: regexp
                span_names:
                    - recv
                    - fs.*
                    - tcp.*
                    - task payment-consumer.scheduled-expired-payment

# Apply filtering to apply only for 4XX and 5XX errors.
    filter/spans3:
        spans:
            include:
                match_type: regexp
                attributes:
                    - key: status
                      value: (4|5).*


# Apply filtering to collect logs where contains traceID=
    filter/logs:
        error_mode: ignore
        logs:
            include:
                match_type: regexp
                bodies:
                    - traceID=(\w+)

# Apply multiple pipelines
service:
    pipelines:
        logs:
            receivers: [  otlp, fluentforward ]
            processors: [ transform/before, attributes, transform/after ]
            exporters: [ debug, elasticsearch/log ]
        logs/2:
            receivers: [  otlp, fluentforward ]
            processors: [ transform/before, attributes, transform/after, filter/logs ]
            exporters: [debug, loki ]
        metrics:
            receivers: [ otlp ]
            processors: [ batch ]
            exporters: [ debug, prometheus ]
        traces:
            receivers: [otlp, zipkin]
            processors: [filter/spans, filter/spans2]
            exporters: [debug, otlp]
        traces/2:
            receivers: [otlp, zipkin]
            processors: [filter/spans, filter/spans3]
            exporters: [debug, otlp, zipkin]
    extensions: [ memory_ballast, zpages, health_check ]